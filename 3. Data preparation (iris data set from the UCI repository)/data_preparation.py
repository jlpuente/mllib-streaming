from pyspark.sql import SparkSession
from pyspark.ml.feature import VectorAssembler


if __name__ == '__main__':

    # Step 1. Create a SparkSession
    spark_session = SparkSession\
        .builder\
        .appName("IrisDataset")\
        .master("local[2]")\
        .getOrCreate()

    # Step 2. Load the iris dataset
    iris = spark_session\
        .read\
        .csv("C:\\Users\\jlpuente\\Documents\\MBD\\M10_Machine_Learning_y_Streaming\\Deliveries"
                                  "\\Mandatories\\3. Data preparation\\iris", header=False, inferSchema=True)

    # Step 3. Generate the feature column names using a loop.
    # Note: iris dataset has 4 features so it can be generated by hand, but what if it had 50?
    num_features = len(iris.columns) - 1
    feature_cols = ["feature_" + str(feature) for feature in range(1, num_features + 1)]

    # Step 4. Define the vector assembler to create a features column
    assembler = VectorAssembler(inputCols=feature_cols, outputCol="features")

    # Step 5. Add a header to the iris dataframe
    iris = iris.toDF(*feature_cols, "label")

    # Step 6. Transform the iris dataframe using the vector assembler
    iris_transformed = assembler.transform(iris).select("features", "label")

    # Step 7. Show the transformed iris dataframe
    iris_transformed.show()

    # Final Step. Stop the SparkSession object
    spark_session.stop()
